# -*- coding: utf-8 -*-
"""
æ ¸å¿ƒå¤„ç†å™¨æ¨¡å—
è´Ÿè´£ç”¨æˆ·ç­”æ¡ˆçš„å¤„ç†å’Œä¸šåŠ¡é€»è¾‘
"""
from core.survey import get_questions_with_options
from ai.ai_analysis import generate_ai_analysis


def process_answers(*args):
    """
    Process user answers and generate analysis results with loading state
    """
    print("ğŸ” process_answers å‡½æ•°è¢«è°ƒç”¨")
    print(f"ğŸ“Š æ”¶åˆ°çš„å‚æ•°æ•°é‡: {len(args)}")

    # æœ€åä¸‰ä¸ªå‚æ•°æ˜¯APIé…ç½®ï¼Œå‰é¢çš„éƒ½æ˜¯ç­”æ¡ˆ
    num_answers = len(args) - 3
    answers = args[:num_answers]
    api_key, base_url, model = args[-3:]

    print(f"ğŸ“Š ç­”æ¡ˆæ•°é‡: {len(answers)}")
    print(f"ğŸ”§ APIé…ç½®: key={api_key[:10]}..., url={base_url}, model={model}")

    # Convert answers to qa_pairs format directly
    qa_pairs = []
    questions = get_questions_with_options()
    print(f"ğŸ“‹ åŠ è½½çš„é—®é¢˜æ•°é‡: {len(questions)}")

    for i, answer in enumerate(answers):
        if i < len(questions):
            question, options = questions[i]
            qa_pairs.append(f"é—®é¢˜: {question}\nå›ç­”: {answer}")

    print(f"ğŸ“ ç»„ç»‡äº†{len(qa_pairs)}ä¸ªé—®ç­”å¯¹")

    # é¦–å…ˆè¿”å›åŠ è½½çŠ¶æ€å’Œè·³è½¬åˆ°ç»“æœé¡µé¢
    loading_message = """ğŸ¤– AIåˆ†æè¿›è¡Œä¸­...

â³ æ­£åœ¨åˆ†ææ‚¨çš„å›ç­”...
â³ æ­£åœ¨ç”Ÿæˆé¢†å¯¼ç±»å‹åˆ¤æ–­...
â³ æ­£åœ¨å‡†å¤‡ä¸ªæ€§åŒ–æ²Ÿé€šå»ºè®®...

è¯·ç¨å€™ï¼Œåˆ†æéœ€è¦10-30ç§’...

ğŸ’¡ æç¤ºï¼šåˆ†æå®Œæˆåå°†è‡ªåŠ¨æ˜¾ç¤ºå®Œæ•´æŠ¥å‘Š"""
    import gradio as gr
    yield loading_message, gr.update(selected=2)

    # Generate AI-powered analysis with qa_pairs directly
    print("ğŸ¤– å¼€å§‹ç”ŸæˆAIåˆ†æ...")
    print("ğŸ“Š æ­£åœ¨å‡†å¤‡æ•°æ®...")
    analysis_result = generate_ai_analysis(qa_pairs, api_key, base_url, model)
    print(f"ğŸ“„ AIåˆ†æç»“æœé•¿åº¦: {len(analysis_result)}")
    print(f"ğŸ“„ AIåˆ†æç»“æœé¢„è§ˆ: {analysis_result[:200]}...")

    print("âœ… process_answers å‡½æ•°æ‰§è¡Œå®Œæˆ")
    yield analysis_result, gr.update(selected=2)